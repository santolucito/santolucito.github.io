# Module 3: Text-to-Image Machine Learning

More details to come

<a name="project3"></a>

## Project 3: Using Text-to-image

- Due Wed Nov 23, 11:59pm

Your goal is to experience first-hand using a text-to-image (Stable Diffusion) to generate a piece of media.

You will need to:

- find a text to use as source material (e.g. project gutenberg https://www.gutenberg.org/)
- compute the most frequent noun phrases (https://github.com/sloria/textblob)
- generate a children's counting book from those noun phrases using Stable Diffusion

This will require you leverage your Python skills from the first half of the class, as well as a bit of prompt engineering.

Optional: fine-tune the model to produce images in a particular style


<hr> 

## Lecture 3-1: Intro to Text-to-image

https://docs.google.com/presentation/d/16KVanb8DUQrtvyibYqlryn-ZnpCHDidwuv-aK8FjnhU/edit?usp=sharing

<hr> 

## Lecture 3-2: Prompt Engineering

<hr> 

## Lab 3: Testing out Stable Diffusion

The goal of this lab is to ensure you are ready to start interfacing with stable diffusion.
Your goal is to explore the impact of the ```inference_steps``` parameter.
Start by setting a random seed, and then design a prompt of your choosing, and generate 10 images, each with an increasing number of ```inference_steps```.
Write up a short description of what you observe.
How does the image change with more inference steps?

You should use this colab notebook as a starting point: https://colab.research.google.com/drive/16vaTJi1o5139AlPPU-k-dggc3bx9qnL1?usp=sharing
Make a copy of the notebook in your own drive, then generate the images.
Turn in your 

<hr> 

## Lecture 3-1: Fine tuning

<hr> 

## Lecture 3-1: More fine tuning and wrappping up
